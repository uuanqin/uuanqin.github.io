{"data":{"title":"免费高效制作精美词云（Python、wordart）","slug":"工具箱/免费高效制作精美词云（Python、wordart）","description":"使用Python进行词频统计后，进入第三方网站导入统计数据生成词云。","date":"2022-03-17T11:06:12.000Z","updated":"2024-08-30T11:16:44.253Z","language":"zh-CN","comments":true,"url":"p/e912a4d6/","cover":"https://cdn.gallery.uuanqin.top/img/wordcloud-cover.png","images":[],"content":"<p>现在网上制作词云的工具太多，但是存在一个问题，就是免费的词云网站制作得丑、不支持中文、没有词频统计，收费的又感觉没那必要。现提供以下简单的词频统计 + 词云制作的方法。</p>\n<p>首先，用到免费的词云制作网站为 <a href=\"http://wordart.com\">wordart.com</a>，是个外国网站，需要导入词频统计数据。里面包含的词云调整功能丰富，可以自定义的地方很多，大家可以自己探索。</p>\n<p>关于中文词频统计，则采用 Python 库进行。这里用到的是 jieba 第三方库，分词较准，灵活操作性强。脚本我已经编写好了，大家只需照做即可 。</p>\n<h1 id=\"一-中文词频统计\"><a class=\"markdownIt-Anchor\" href=\"#一-中文词频统计\"></a> 一、中文词频统计</h1>\n<p>编写以下 Python 脚本：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> jieba</span><br><span class=\"line\"><span class=\"keyword\">import</span> jieba.posseg <span class=\"keyword\">as</span> pseg</span><br><span class=\"line\"></span><br><span class=\"line\">in_file_name = <span class=\"string\">&quot;text.txt&quot;</span>                   <span class=\"comment\"># 要分析的文本</span></span><br><span class=\"line\">user_dict_name = <span class=\"string\">&quot;user_dict.txt&quot;</span>            <span class=\"comment\"># 用户自定义词典</span></span><br><span class=\"line\">block_words_name = <span class=\"string\">&quot;block_words.txt&quot;</span>        <span class=\"comment\"># 屏蔽词</span></span><br><span class=\"line\">out_file_name = <span class=\"string\">&#x27;out.csv&#x27;</span>                   <span class=\"comment\"># 词频统计数据的输出</span></span><br><span class=\"line\">block_word_class = [<span class=\"string\">&quot;c&quot;</span>,<span class=\"string\">&quot;uj&quot;</span>,<span class=\"string\">&quot;p&quot;</span>,<span class=\"string\">&quot;r&quot;</span>,<span class=\"string\">&quot;ul&quot;</span>]  <span class=\"comment\"># 屏蔽词性</span></span><br><span class=\"line\">regex = <span class=\"string\">&#x27;^[\\u4E00-\\u9FA5A-Za-z0-9]+$&#x27;</span>       <span class=\"comment\"># 除去标点符号，只保留中英文和数字</span></span><br><span class=\"line\"></span><br><span class=\"line\">data = <span class=\"built_in\">open</span>(in_file_name, <span class=\"string\">&quot;r&quot;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>).read()     <span class=\"comment\"># 打开文件</span></span><br><span class=\"line\">jieba.load_userdict(user_dict_name)                         <span class=\"comment\"># 加载用户自定义词典</span></span><br><span class=\"line\">seg_list = pseg.cut(data,use_paddle=<span class=\"literal\">True</span>)                   <span class=\"comment\"># 默认是精确模式</span></span><br><span class=\"line\">block_words_file = <span class=\"built_in\">open</span>(block_words_name,<span class=\"string\">&quot;r&quot;</span>,encoding=<span class=\"string\">&quot;utf-8&quot;</span>)  <span class=\"comment\"># 打开屏蔽词库</span></span><br><span class=\"line\">reader = csv.reader(block_words_file)</span><br><span class=\"line\">block_words = [w[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> reader]                        <span class=\"comment\"># 生成屏蔽词列表</span></span><br><span class=\"line\">words = &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 统计</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">str</span>,flag <span class=\"keyword\">in</span> seg_list:</span><br><span class=\"line\">    <span class=\"comment\"># 屏蔽词、屏蔽词性</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> flag <span class=\"keyword\">in</span> block_word_class <span class=\"keyword\">or</span> <span class=\"built_in\">str</span> <span class=\"keyword\">in</span> block_words:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> re.search(regex, <span class=\"built_in\">str</span>):</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            words[<span class=\"built_in\">str</span>]</span><br><span class=\"line\">        <span class=\"keyword\">except</span> KeyError:</span><br><span class=\"line\">            words[<span class=\"built_in\">str</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        words[<span class=\"built_in\">str</span>] = words[<span class=\"built_in\">str</span>] + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 写</span></span><br><span class=\"line\">out = <span class=\"built_in\">open</span>(out_file_name, <span class=\"string\">&#x27;w&#x27;</span>, newline=<span class=\"string\">&quot;&quot;</span>, encoding=<span class=\"string\">&quot;utf-8&quot;</span>)  <span class=\"comment\"># 注意，这里使用&quot;w&quot;不是&quot;wb&quot;，否则报错</span></span><br><span class=\"line\">writer = csv.writer(out,delimiter=<span class=\"string\">&quot;\\t&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(words.items(), key=<span class=\"keyword\">lambda</span> k: k[<span class=\"number\">1</span>], reverse=<span class=\"literal\">True</span>):</span><br><span class=\"line\">    writer.writerow([k,v])</span><br></pre></td></tr></table></figure>\n<p>代码的第一段可根据自己的需求进行更改。现对这些参数进行解释。</p>\n<h2 id=\"1-需要分析的文本文件-in_file_name\"><a class=\"markdownIt-Anchor\" href=\"#1-需要分析的文本文件-in_file_name\"></a> 1. 需要分析的文本文件 <code>in_file_name</code></h2>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163304.png\" alt=\"\" /></p>\n<p>在同目录下准备以下三个文件：需要分析的文本文件、用户自定义词典、屏蔽词库。将需要分析的文本文件名填入 in_file_name 中。</p>\n<p>示例中，test.txt 包含需要词频统计的内容。</p>\n<h2 id=\"2-用户自定义词典-user_dict_name\"><a class=\"markdownIt-Anchor\" href=\"#2-用户自定义词典-user_dict_name\"></a> 2. 用户自定义词典 <code>user_dict_name</code></h2>\n<p>此处脚本中，使用 jieba 默认的精确模式，会自动识别新词。但如果自己想添加自定义的词，可以在新的文本文件（utf-8）中按照以下方式进行添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">创新办 3 i</span><br><span class=\"line\">云计算 5</span><br><span class=\"line\">凱特琳 nz</span><br><span class=\"line\">台中</span><br></pre></td></tr></table></figure>\n<p>一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。</p>\n<p>词性表参见 <a href=\"https://github.com/fxsjy/jieba\">fxsjy/jieba: 结巴中文分词 (github.com)</a></p>\n<p>比如：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163312.png\" alt=\"\" width=\"425px\" /></p>\n<p>关于 jieba 库的使用参见：<a href=\"https://github.com/fxsjy/jieba\">fxsjy/jieba: 结巴中文分词 (github.com)</a></p>\n<h2 id=\"3-屏蔽词库-block_words_name\"><a class=\"markdownIt-Anchor\" href=\"#3-屏蔽词库-block_words_name\"></a> 3. 屏蔽词库 <code>block_words_name</code></h2>\n<p>新建一个文本文件，在里面添加不需要进行词频统计的词。一行一词。</p>\n<p>比如：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163322.png\" alt=\"\" width=\"425px\" /></p>\n<h2 id=\"4-输出的-csv-文件名-out_file_name\"><a class=\"markdownIt-Anchor\" href=\"#4-输出的-csv-文件名-out_file_name\"></a> 4. 输出的 <code>.csv</code> 文件名 <code>out_file_name</code></h2>\n<p>指定输出的.csv 文件名。</p>\n<h2 id=\"5可选屏蔽词性-block_word_class\"><a class=\"markdownIt-Anchor\" href=\"#5可选屏蔽词性-block_word_class\"></a> 5.（可选）屏蔽词性 <code>block_word_class</code></h2>\n<p>指定不需要进行词频统计的词的词性。词性列表参见下文。这里默认屏蔽连词、助词、介词、代词。</p>\n<h2 id=\"6可选保留词的正则表达式-regex\"><a class=\"markdownIt-Anchor\" href=\"#6可选保留词的正则表达式-regex\"></a> 6.（可选）保留词的正则表达式 regex</h2>\n<p>指定需要进行词频统计的词的正则表达式。这里默认为中文、英文和数字。</p>\n<p>当一切准备好后，运行脚本。</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163500.png\" alt=\"\" width=\"500px\" /></p>\n<p>输出：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163340.png\" alt=\"\" width=\"500px\" /></p>\n<h1 id=\"二-wordart-网站设置\"><a class=\"markdownIt-Anchor\" href=\"#二-wordart-网站设置\"></a> 二、WordArt 网站设置</h1>\n<p>运行以上脚本，复制输出的内容后。打开网站 <a href=\"https://wordart.com/create\">Word Art - Edit - WordArt.com</a>。</p>\n<h2 id=\"1-导入统计信息\"><a class=\"markdownIt-Anchor\" href=\"#1-导入统计信息\"></a> 1. 导入统计信息</h2>\n<p>点击导入：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163024.png\" alt=\"\" width=\"500px\" /></p>\n<p>粘贴，并按照以下设置：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163052.png\" alt=\"\" width=\"500px\" /></p>\n<p>导入成功：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317163100.png\" alt=\"\" width=\"475px\" /></p>\n<p>其他自定义操作可自行在网站上操作。</p>\n<h2 id=\"2-导入字体\"><a class=\"markdownIt-Anchor\" href=\"#2-导入字体\"></a> 2. 导入字体</h2>\n<p>网站支持英文词云。如果想让中文词云也能生成，就必须上传一款中文字体。中文字体可以在系统字体（Fonts 文件夹）中找：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/选择字体-1024x360.png\" alt=\"\" /></p>\n<p>导入字体后：</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317162823.png\" alt=\"\" width=\"475px\" /></p>\n<h2 id=\"3-选择形状\"><a class=\"markdownIt-Anchor\" href=\"#3-选择形状\"></a> 3. 选择形状</h2>\n<p>可以在网站图库中选。这里我采用自己上传的方式。注意，上传 PNG 图片更好。</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317162957-1024x753.png\" alt=\"\" /></p>\n<p>至于词云中其他自定义设定可以自行探索。</p>\n<h2 id=\"4-生成\"><a class=\"markdownIt-Anchor\" href=\"#4-生成\"></a> 4. 生成</h2>\n<p>准备好了之后，点击生成按钮。</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/QQ截图20220317162704.png\" alt=\"\" width=\"500px\" /></p>\n<p>当当当当！生成成功。</p>\n<p><img src= \"/image/loading.gif\" data-lazy-src=\"https://cdn.gallery.uuanqin.top/img/res.png\" alt=\"\" width=\"500px\" /></p>\n<h1 id=\"参考连接\"><a class=\"markdownIt-Anchor\" href=\"#参考连接\"></a> 参考连接</h1>\n<ul>\n<li>不同的词频统计第三方库：<a href=\"https://www.jianshu.com/p/7ad0cd33005e\">Python中文分词及词频统计 - 简书 (jianshu.com)</a></li>\n<li>csv 库官方文档：<a href=\"https://docs.python.org/3/library/csv.html\">csv — CSV File Reading and Writing — Python 3.10.2 documentation</a></li>\n</ul>\n","raw":"---\ntitle: 免费高效制作精美词云（Python、wordart）\ntags:\n  - Python\n  - 实现\n  - 词云\n  - 词频统计\n  - wordart\ncategories:\n  - 工具箱\ncover: 'https://cdn.gallery.uuanqin.top/img/wordcloud-cover.png'\ndescription: 使用Python进行词频统计后，进入第三方网站导入统计数据生成词云。\nabbrlink: e912a4d6\ndate: 2022-03-17 19:06:12\n---\n\n现在网上制作词云的工具太多，但是存在一个问题，就是免费的词云网站制作得丑、不支持中文、没有词频统计，收费的又感觉没那必要。现提供以下简单的词频统计 + 词云制作的方法。\n\n首先，用到免费的词云制作网站为 [wordart.com](http://wordart.com)，是个外国网站，需要导入词频统计数据。里面包含的词云调整功能丰富，可以自定义的地方很多，大家可以自己探索。\n\n关于中文词频统计，则采用 Python 库进行。这里用到的是 jieba 第三方库，分词较准，灵活操作性强。脚本我已经编写好了，大家只需照做即可 。\n\n# 一、中文词频统计\n\n编写以下 Python 脚本：\n\n```python\nimport csv\nimport re\nimport jieba\nimport jieba.posseg as pseg\n\nin_file_name = \"text.txt\"                   # 要分析的文本\nuser_dict_name = \"user_dict.txt\"            # 用户自定义词典\nblock_words_name = \"block_words.txt\"        # 屏蔽词\nout_file_name = 'out.csv'                   # 词频统计数据的输出\nblock_word_class = [\"c\",\"uj\",\"p\",\"r\",\"ul\"]  # 屏蔽词性\nregex = '^[\\u4E00-\\u9FA5A-Za-z0-9]+$'       # 除去标点符号，只保留中英文和数字\n\ndata = open(in_file_name, \"r\", encoding='utf-8').read()     # 打开文件\njieba.load_userdict(user_dict_name)                         # 加载用户自定义词典\nseg_list = pseg.cut(data,use_paddle=True)                   # 默认是精确模式\nblock_words_file = open(block_words_name,\"r\",encoding=\"utf-8\")  # 打开屏蔽词库\nreader = csv.reader(block_words_file)\nblock_words = [w[0] for w in reader]                        # 生成屏蔽词列表\nwords = {}\n\n# 统计\nfor str,flag in seg_list:\n    # 屏蔽词、屏蔽词性\n    if flag in block_word_class or str in block_words:\n        continue\n    if re.search(regex, str):\n        try:\n            words[str]\n        except KeyError:\n            words[str] = 0\n        words[str] = words[str] + 1\n\n# 写\nout = open(out_file_name, 'w', newline=\"\", encoding=\"utf-8\")  # 注意，这里使用\"w\"不是\"wb\"，否则报错\nwriter = csv.writer(out,delimiter=\"\\t\")\nfor k, v in sorted(words.items(), key=lambda k: k[1], reverse=True):\n    writer.writerow([k,v])\n```\n\n代码的第一段可根据自己的需求进行更改。现对这些参数进行解释。\n\n## 1. 需要分析的文本文件 `in_file_name`\n\n![](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163304.png)\n\n在同目录下准备以下三个文件：需要分析的文本文件、用户自定义词典、屏蔽词库。将需要分析的文本文件名填入 in\\_file\\_name 中。\n\n示例中，test.txt 包含需要词频统计的内容。\n\n## 2. 用户自定义词典 `user_dict_name`\n\n此处脚本中，使用 jieba 默认的精确模式，会自动识别新词。但如果自己想添加自定义的词，可以在新的文本文件（utf-8）中按照以下方式进行添加：\n\n```\n创新办 3 i\n云计算 5\n凱特琳 nz\n台中\n```\n\n一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。\n\n词性表参见 [fxsjy/jieba: 结巴中文分词 (github.com)](https://github.com/fxsjy/jieba)\n\n比如：\n\n![|425](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163312.png)\n\n关于 jieba 库的使用参见：[fxsjy/jieba: 结巴中文分词 (github.com)](https://github.com/fxsjy/jieba)\n\n## 3. 屏蔽词库 `block_words_name`\n\n新建一个文本文件，在里面添加不需要进行词频统计的词。一行一词。\n\n比如：\n\n![|425](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163322.png)\n\n## 4. 输出的 `.csv` 文件名 `out_file_name`\n\n指定输出的.csv 文件名。\n\n## 5.（可选）屏蔽词性 `block_word_class`\n\n指定不需要进行词频统计的词的词性。词性列表参见下文。这里默认屏蔽连词、助词、介词、代词。\n\n## 6.（可选）保留词的正则表达式 regex\n\n指定需要进行词频统计的词的正则表达式。这里默认为中文、英文和数字。\n\n当一切准备好后，运行脚本。\n\n![|500](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163500.png)\n\n输出：\n\n![|500](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163340.png)\n\n# 二、WordArt 网站设置\n\n运行以上脚本，复制输出的内容后。打开网站 [Word Art - Edit - WordArt.com](https://wordart.com/create)。\n\n## 1. 导入统计信息\n\n点击导入：\n\n![|500](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163024.png)\n\n粘贴，并按照以下设置：\n\n![|500](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163052.png)\n\n导入成功：\n\n![|475](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317163100.png)\n\n其他自定义操作可自行在网站上操作。\n\n## 2. 导入字体\n\n网站支持英文词云。如果想让中文词云也能生成，就必须上传一款中文字体。中文字体可以在系统字体（Fonts 文件夹）中找：\n\n![](https://cdn.gallery.uuanqin.top/img/%E9%80%89%E6%8B%A9%E5%AD%97%E4%BD%93-1024x360.png)\n\n导入字体后：\n\n![|475](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317162823.png)\n\n## 3. 选择形状\n\n可以在网站图库中选。这里我采用自己上传的方式。注意，上传 PNG 图片更好。\n\n![](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317162957-1024x753.png)\n\n至于词云中其他自定义设定可以自行探索。\n\n## 4. 生成\n\n准备好了之后，点击生成按钮。\n\n![|500](https://cdn.gallery.uuanqin.top/img/QQ%E6%88%AA%E5%9B%BE20220317162704.png)\n\n当当当当！生成成功。\n\n![|500](https://cdn.gallery.uuanqin.top/img/res.png)\n\n# 参考连接\n\n- 不同的词频统计第三方库：[Python中文分词及词频统计 - 简书 (jianshu.com)](https://www.jianshu.com/p/7ad0cd33005e)\n- csv 库官方文档：[csv — CSV File Reading and Writing — Python 3.10.2 documentation](https://docs.python.org/3/library/csv.html)","categories":[{"name":"工具箱","api":"api/categories/工具箱.json"}],"tags":[{"name":"Python","api":"api/tags/Python.json"},{"name":"实现","api":"api/tags/实现.json"},{"name":"词云","api":"api/tags/词云.json"},{"name":"词频统计","api":"api/tags/词频统计.json"},{"name":"wordart","api":"api/tags/wordart.json"}]},"api":"api/posts/p/e912a4d6.json"}