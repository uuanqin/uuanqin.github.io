{"title":"免费高效制作精美词云（Python、wordart）","tags":["Python","实现","词云","词频统计","wordart"],"categories":["工具箱"],"cover":"https://cdn.gallery.uuanqin.top/img/wordcloud-cover.png","description":"使用Python进行词频统计后，进入第三方网站导入统计数据生成词云。","abbrlink":"e912a4d6","date":"2022-03-17T19:06:12.000Z","summary":"现在网上制作词云的工具太多，但是存在一个问题，就是免费的词云网站制作得丑、不支持中文、没有词频统计，收费的又感觉没那必要。现提供以下简单的词频统计 + 词云制作的方法。 首先，用到免费的词云制作网站为 wordart.com，是个外国网站，需要导入词频统计数据。里面包含的词云调整功能丰富，可以自定义的地方很多，大家可以自己探索。 关于中文词频统计，则采用 Python 库进行。这里用到的是 jieba 第三方库，分词较准，灵活操作性强。脚本我已经编写好了，大家只需照做即可 。 一、中文词频统计 编写以下 Python 脚本： 代码的第一段可根据自己的需求进行更改。现对这些参数进行解释。 需要分析的文本文件 `in_file_name` 在同目录下准备以下三个文件：需要分析的文本文件、用户自定义词典、屏蔽词库。将需要分析的文本文件名填入 in\\_file\\_name 中。 示例中，test.txt 包含需要词频统计的内容。 用户自定义词典 `user_dict_name` 此处脚本中，使用 jieba 默认的精确模式，会自动识别新词。但如果自己想添加自定义的词，可以在新的文本文件（utf-8）中按照以下方式进行添加： 一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。 词性表参见 fxsjy/jieba: 结巴中文分词 (github.com) 比如： 关于 jieba 库的使用参见：fxsjy/jieba: 结巴中文分词 (github.com) 屏蔽词库 `block_words_name` 新建一个文本文件，在里面添加不需要进行词频统计的词。一行一词。 比如： 输出的 `.csv` 文件名 `out_file_name` 指定输出的.csv 文件名。 5.（可选）屏蔽词性 `block_word_class` 指定不需要进行词频统计的词的词性。词性列表参见下文。这里默认屏蔽连词、助词、介词、代词。 6.（可选）保留词的正则表达式 regex 指定需要进行词频统计的词的正则表达式。这里默认为中文、英文和数字。 当一切准备好后，运行脚本。 输出： 二、WordArt 网站设置 运行以上脚本，复制输出的内容后。打开网站 Word Art - Edit - WordArt.com。..."}